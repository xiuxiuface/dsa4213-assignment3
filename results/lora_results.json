{
  "timestamp": "2025-10-21T02:04:58.077842",
  "config": {
    "model_name": "distilbert-base-uncased",
    "dataset_name": "imdb",
    "max_length": 512,
    "batch_size": 16,
    "learning_rate": 2e-05,
    "num_epochs": 3,
    "seed": 42,
    "output_dir": "/kaggle/working/results",
    "lora_r": 8,
    "lora_alpha": 32,
    "lora_dropout": 0.1
  },
  "results": {
    "strategy": "LoRA Fine-tuning",
    "accuracy": 0.90092,
    "f1": 0.9014521583449373,
    "model_size": 67768324,
    "trainable_params": 813314,
    "lora_config": {
      "r": 8,
      "alpha": 32,
      "dropout": 0.1
    }
  }
}